# Convolabs AI: Voice Assistant & Website ðŸŒðŸŽ¤ðŸ¤–

Welcome to the **Convolabs AI** repository! This project is designed to create a seamless AI-powered voice assistant and website experience. The project is divided into three major parts, each leveraging cutting-edge AI models to deliver a robust and interactive system. Let's dive into the details! ðŸš€

------
# React + Vite

This template provides a minimal setup to get React working in Vite with HMR and some ESLint rules.

## ðŸŽ¯ Project Overview

The Convolabs AI project is structured into three core components:

1. **Speech to Text (STT)** ðŸŽ¤âž¡ï¸ðŸ“
2. **Fine-tuned LLM Response** ðŸ¤–ðŸ’¬
3. **Text to Speech (TTS)** ðŸ“âž¡ï¸ðŸŽ§

This repository focuses on **Part 1 (Speech to Text)** and **Part 3 (Text to Speech)**. The second part, involving the fine-tuned LLM, is handled externally.

---

## ðŸ› ï¸ Tech Stack & Tools

- **Groq API**: For Speech-to-Text using the `whisper-large-v3` model.
- **Llama3.1**: Fine-tuned LLM for generating responses.
- **Kokoro-v0_19**: Text-to-Speech model for converting text into audio.
- **Python**: Backend logic and API handling.
- **JavaScript**: Microphone access and audio playback.
- **Environment Variables**: Secure handling of API keys and configurations.

---

## ðŸš€ Pipeline Breakdown

### 1. **Speech to Text (STT)** ðŸŽ¤âž¡ï¸ðŸ“
- We use the **Groq API** with the `whisper-large-v3` model to convert audio files into text.
- The audio file is passed to the API with appropriate headers, and the response is received in JSON format.
- The extracted text is then passed to the next stage.

### 2. **Fine-tuned LLM Response** ðŸ¤–ðŸ’¬
- The text from Part 1 is fed into the **Llama3.1** model, which is fine-tuned to act as a customer care assistant.
- The model generates a response, which is then passed to the Text-to-Speech model.

### 3. **Text to Speech (TTS)** ðŸ“âž¡ï¸ðŸŽ§
- The response from Part 2 is divided into chunks of 490 characters.
- These chunks are fed into the **Kokoro-v0_19** model, which converts the text into a `.wav` audio file.
- The audio file is saved as `output.wav` and played back using JavaScript.

---

## ðŸ› ï¸ Installation & Setup

To get started with the Convolabs AI project, follow these steps:

### Step 1: Install Git LFS (Large File Storage)
```bash
git lfs install

cd Kokoro-82M

sudo apt-get -qq -y install espeak-ng > /dev/null 2>&1

pip install -q phonemizer torch transformers scipy munch

pip install -r requirements.txt

cd myproject

python manage.py runserver
